{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Python - Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, HTML, Image\n",
    "from IPython.display import SVG\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from TAS_Python_Utilities import data_viz\n",
    "from TAS_Python_Utilities import visualize_tree\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Merge, Dropout\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.vis_utils import model_to_dot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "abt = pd.read_csv(\"mnist_train_small.csv\", encoding = \"ISO-8859-1\")\n",
    "\n",
    "# Put all but the target variable into the descriptive features array\n",
    "X = abt[abt.columns.difference([\"value\"])]\n",
    "Y = abt[\"value\"]\n",
    "\n",
    "# Use a range scaling to scale all variables to between 0 and 1\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "cols = X.columns\n",
    "X = pd.DataFrame(min_max_scaler.fit_transform(X), columns = cols) # Watch out for putting back in columns here\n",
    "\n",
    "X_train_plus_valid, X_test, y_train_plus_valid, y_test = train_test_split(X, Y, random_state=0, test_size = 0.30, train_size = 0.7)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_plus_valid, y_train_plus_valid, random_state=0, test_size = 0.199/0.7, train_size = 0.5/0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_plus_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Specfiy the structure of the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim=784, units=512))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dense(units=207))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dense(units=102))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the parameters of the model optimisation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert the singl column label into a dummy coded label\n",
    "y_train_wide = to_categorical(np.asarray(y_train))\n",
    "y_valid_wide = to_categorical(np.asarray(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(np.asfarray(X_train), np.asfarray(y_train_wide), \\\n",
    "          epochs=20, batch_size=32, verbose=1, \\\n",
    "          validation_data=(np.asfarray(X_valid), np.asfarray(y_valid_wide)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"******** Training Data ********\")\n",
    "# Make a set of predictions for the training data\n",
    "y_pred = model.predict_classes(np.asfarray(X_train), batch_size=32)\n",
    "\n",
    "# Print performance details\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(y_train, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "\n",
    "\n",
    "print(\"****** Validation Data ********\")\n",
    "\n",
    "# Make a set of predictions for the validation data\n",
    "y_pred = model.predict_classes(np.asfarray(X_valid))\n",
    "\n",
    "# Print performance details\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(y_valid, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "print(\"****** Test Data ********\")\n",
    "\n",
    "# Make a set of predictions for the validation data\n",
    "y_pred = model.predict_classes(np.asfarray(X_test))\n",
    "\n",
    "# Print performance details\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Better Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more complicated model - based on [https://raw.githubusercontent.com/fchollet/keras/master/examples/mnist_mlp.py](https://raw.githubusercontent.com/fchollet/keras/master/examples/mnist_mlp.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_mlp = Sequential()\n",
    "model_mlp.add(Dense(512, input_shape=(784,)))\n",
    "model_mlp.add(Activation('relu'))\n",
    "model_mlp.add(Dropout(0.2))\n",
    "model_mlp.add(Dense(512))\n",
    "model_mlp.add(Activation('relu'))\n",
    "model_mlp.add(Dropout(0.2))\n",
    "model_mlp.add(Dense(10))\n",
    "model_mlp.add(Activation('softmax'))\n",
    "\n",
    "model_mlp.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Convert the singl column label into a dummy coded label\n",
    "y_train_wide = to_categorical(np.asarray(y_train))\n",
    "y_valid_wide = to_categorical(np.asarray(y_valid))\n",
    "model_mlp.fit(np.asfarray(X_train), np.asfarray(y_train_wide), \\\n",
    "          epochs=20, batch_size=32, verbose=1, \\\n",
    "          validation_data=(np.asfarray(X_valid), np.asfarray(y_valid_wide)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"******** Training Data ********\")\n",
    "# Make a set of predictions for the training data\n",
    "y_pred = model_mlp.predict_classes(np.asfarray(X_train), batch_size=32)\n",
    "\n",
    "# Print performance details\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(y_train, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "\n",
    "\n",
    "print(\"****** Validation Data ********\")\n",
    "\n",
    "# Make a set of predictions for the validation data\n",
    "y_pred = model_mlp.predict_classes(np.asfarray(X_valid))\n",
    "\n",
    "# Print performance details\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(y_valid, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"****** Test Data ********\")\n",
    "\n",
    "# Make a set of predictions for the validation data\n",
    "y_pred = model_mlp.predict_classes(np.asfarray(X_test))\n",
    "\n",
    "# Print performance details\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model_mlp).create(prog='dot', format='svg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
